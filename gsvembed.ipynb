{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure to install the packages in the requirements.txt file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GSV_API_KEY\")\n",
    "\n",
    "# to keep API your key private, create a .env file in your project directory\n",
    "# and assign some name, for example, \"GSV_API_KEY\" to your API key, for example,\n",
    "# GSV_API_KEY=[my_api_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import cv2\n",
    "\n",
    "headings = [0, 90, 180, 270]\n",
    "generated_locs_fp = 'chile1000locs.json'\n",
    "\n",
    "with open(generated_locs_fp, 'r') as f:\n",
    "    locs  = json.load(f)\n",
    "\n",
    "#iterate through coordinate pairs of json of generated locs and request 4 images for each cardinal direction heading from the GSV API\n",
    "for i, loc in enumerate(locs):\n",
    "    lat, lon = loc[\"lat\"], loc[\"lng\"]\n",
    "    location_folder = os.path.join('panoramas', f\"location_{i}\")\n",
    "    os.makedirs(location_folder, exist_ok=True)\n",
    "\n",
    "    images = []\n",
    "    for heading in headings:\n",
    "        url = f\"https://maps.googleapis.com/maps/api/streetview?size=256x256&location={lat},{lon}&heading={heading}&key={api_key}&fov=105\"\n",
    "        response = requests.get(url)\n",
    "\n",
    "        img_path = os.path.join(location_folder, f\"heading_{heading}.jpg\")\n",
    "        with open(img_path, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        images.append(cv2.imread(img_path))\n",
    "    \n",
    "    #stitch pano by concatenating the 4 images horizontally\n",
    "    stitched_pano = cv2.hconcat(images)\n",
    "    pano_path = os.path.join(location_folder, \"stitched_panorama.jpg\")\n",
    "    cv2.imwrite(pano_path, stitched_pano)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After generating the stitched panos, we will run them through the StreetCLIP model to generate embeddings. A metadata map is created between each of the location file paths and embedding file paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "import torch\n",
    "\n",
    "model = CLIPModel.from_pretrained(\"geolocal/StreetCLIP\")\n",
    "processor = CLIPProcessor.from_pretrained(\"geolocal/StreetCLIP\")\n",
    "\n",
    "pano_folder = 'panoramas'\n",
    "output_embeddings_folder = \"embeddings\"\n",
    "os.makedirs(output_embeddings_folder, exist_ok=True)\n",
    "\n",
    "embedding_metadata = []\n",
    "\n",
    "for loc_folder in os.listdir(pano_folder):\n",
    "    loc_path = os.path.join(pano_folder, loc_folder)\n",
    "    if os.path.isdir(loc_path):\n",
    "        panorama_path = os.path.join(loc_path, \"stitched_panorama.jpg\")\n",
    "        pano_image = Image.open(panorama_path)\n",
    "\n",
    "        inputs = processor(images = pano_image, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            embeddings = model.get_image_features(**inputs)\n",
    "\n",
    "        #L2 normalization--want to ensure uniform scale but retain original dimensionality\n",
    "        embeddings = embeddings / torch.linalg.vector_norm(embeddings, ord=2, dim=-1, keepdim=True)\n",
    "\n",
    "        embedding_path = os.path.join(output_embeddings_folder, f\"{loc_folder}_embedding.pt\")\n",
    "        torch.save(embeddings, embedding_path)\n",
    "\n",
    "        embedding_metadata.append({\n",
    "            \"location_id\": loc_folder,\n",
    "            \"embedding_path\": embedding_path,\n",
    "            \"panorama_path\": panorama_path\n",
    "        })\n",
    "\n",
    "metadata_path = os.path.join(output_embeddings_folder, \"embedding_metadata_t2.json\")\n",
    "with open(metadata_path, \"w\") as f:\n",
    "    json.dump(embedding_metadata, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "embedding_metadata_path = \"embeddings/embedding_metadata_t2.json\"\n",
    "with open(embedding_metadata_path, \"r\") as f:\n",
    "    embedding_metadata = json.load(f)\n",
    "\n",
    "embeddings = []\n",
    "locations = []\n",
    "\n",
    "total_locations = 1000\n",
    "\n",
    "for i in range(0, total_locations):  \n",
    "    file_name = f\"location_{i}_embedding.pt\"\n",
    "    file_path = f\"embeddings/{file_name}\"\n",
    "    embedding = torch.load(file_path).numpy()\n",
    "    embeddings.append(embedding.flatten())  # flatten to ensure 1D\n",
    "    locations.append(f\"location_{i}\")\n",
    "\n",
    "embeddings = np.array(embeddings)\n",
    "\n",
    "def cluster_embeddings(embeddings, n_clusters):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    labels = kmeans.fit_predict(embeddings)\n",
    "\n",
    "    silhouette_avg = silhouette_score(embeddings, labels)\n",
    "    print(f\"Silhouette Score: {silhouette_avg}\")\n",
    "\n",
    "    return labels, kmeans.cluster_centers_\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# dimensionality reduction\n",
    "pca = PCA(n_components=50)\n",
    "reduced_embeddings = pca.fit_transform(embeddings)\n",
    "\n",
    "\"\"\"\n",
    "code for comparing silhouette scores between diff # of clusters\n",
    "\n",
    "silhouette_scores = []\n",
    "for k in range(2, 21):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    labels = kmeans.fit_predict(embeddings)\n",
    "    score = silhouette_score(embeddings, labels)\n",
    "    silhouette_scores.append(score)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(2, 21), silhouette_scores)\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.xaxis.set_major_locator(ticker.MaxNLocator(integer=True))\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Score for different values of k')\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.07047548145055771\n",
      "Silhouette Score: 0.11749286204576492\n"
     ]
    }
   ],
   "source": [
    "n_clusters = 5\n",
    "cluster_labels, cluster_centers = cluster_embeddings(embeddings, n_clusters)\n",
    "rd_cluster_labels, rd_cluster_centers = cluster_embeddings(reduced_embeddings, n_clusters)\n",
    "\n",
    "cluster_results = {}\n",
    "for label, location in zip(cluster_labels, locations):\n",
    "    if label not in cluster_results:\n",
    "        cluster_results[int(label)] = []\n",
    "    cluster_results[int(label)].append(location)\n",
    "\n",
    "output_clusters_path = f\"cluster_results.json\"\n",
    "with open(output_clusters_path, \"w\") as f:\n",
    "    json.dump(cluster_results, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First try, using n_clusters = 18, resulted in a very low Silhouette Score of 0.051498. lesser clusters results in higher silhouette score, as well as dimensionality reduction. Can try other clustering method such as DBSCAN  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to create output file, duplicate of original json, but with \"extra\":{\"tags\":[\"str(clusterid)\"]} as a k:v pair for each location object in the JSON, so we can import this into map-making.app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_json = 'chile1000locs.json'\n",
    "with open(original_json, \"r\") as f:\n",
    "    locs = json.load(f)\n",
    "\n",
    "for i, location in enumerate(locs):\n",
    "    if \"extra\" not in location:\n",
    "        location[\"extra\"] = {}\n",
    "    if \"tags\" not in location[\"extra\"]:\n",
    "        location[\"extra\"][\"tags\"] = []\n",
    "\n",
    "    cluster_id = str(int(rd_cluster_labels[i]))\n",
    "    location[\"extra\"][\"tags\"].append(cluster_id)\n",
    "\n",
    "new_json = f'locations_tagged_{n_clusters}_clusters.json'\n",
    "with open(new_json, \"w\") as f:\n",
    "    json.dump(locs, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
